

<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="">
    <meta name="author" content="">
    <link rel="icon" href="../../favicon.ico">

    <title>Lexical Normalisation for English Tweets</title>

    <!-- Bootstrap core CSS -->
    <link href="./dist/css/bootstrap.min.css" rel="stylesheet">

    <!-- Custom styles for this template -->
    <link href="navbar-fixed-top.css" rel="stylesheet">

    <!-- HTML5 shim and Respond.js for IE8 support of HTML5 elements and media queries -->
    <!--[if lt IE 9]>
      <script src="https://oss.maxcdn.com/html5shiv/3.7.2/html5shiv.min.js"></script>
      <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
    <![endif]-->
    
  <style>
 
  </style>
  </head>

  <body >

    <!-- Fixed navbar -->
    <nav class="navbar navbar-default navbar-fixed-top" role="navigation">
      <div class="container">
        <div class="navbar-header">
          <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false" aria-controls="navbar">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
          </button>
          <a class="navbar-brand" href="./index.html">W-NUT</a>
        </div>
        <div id="navbar" class="navbar-collapse collapse">
          <ul class="nav navbar-nav">
            <li class="active"><a href="#">Home</a></li>
            <li><a href="#task">Tasks</a></li>
            <li><a href="#resource">Resources</a></li>
            <li><a href="#date">Important Dates</a></li>
            <li><a href="#committee">Organizer</a></li>
            <li><a href="#reference">References</a></li>
          </ul>
        </div><!--/.nav-collapse -->
      </div>
    </nav>

    <div class="container">

      <!-- Main component for a primary marketing message or call to action -->
      <div class="jumbotron" >
        <h2>Lexical Normalisation for English Tweets</h2>
        <p>Social media data such as Twitter messages is notoriously noisy user generated contents (UGC). It often contains ungrammatical sentence structures, non-standard words and domain-specific entities. Accuracy declines have been observed in many NLP tasks and applications operating on UGC data (Gimpel et al. 2011, Liu et al. 2011). This shared-task aims to normalise non-standard words to their canonical forms for English Twitter messages. After text normalisation, misspelling are corrected (e.g., <i>toook</i> for <i>took</i>), informal abbreviation are expanded (e.g., <i>tmrw</i> for <i>tomorrow</i>) and phonetic substitutions are recovered (e.g., <i>4eva</i> for <i>forever</i>). Recently research communities have embraced many text normalisation methods to alleviate the negative impact of non-standard words. This shared task aims to advance the research on text normalisation in social media by comparing and evaluating various approaches using the same large dataset.</p>
      </div>


<a id="task" ><h2  style="padding-top:50px; margin-top:-50px;">Tasks</h2></a>
<p>To make the evaluation tractable, this task focuses on context-sensitive lexical normalisation of English Twitter messages with following constraints:</p>
<ol>
    <li>Non-standard words (NSWs) are normalised to one or more canonical English words relative to the given lexicon. For instance, <i>l o v e</i> is normalised to <i>love</i>, <i>tmrw</i> is normalised to <i>tomorrow</i> and <i>cu</i> is normalised to <i>see you</i>. Additionally, <i>IBM</i> is kept untouched as it is in the lexicon and a informal </i>lol</i> shall be expanded to <i>laughing out loud</i>.</li>
    <li>Non-standard words may be Out-of-Vocabulary (OOV) tokens (e.g., <i>tmrw</i> for <i>tomorrow</i>) or In-Vocabulary (IV) tokens (e.g., <i>wit</i> for <i>with</i> in <i>I will come wit you</i>).</li>
    <li>Only alphanumeric tokens (e.g., <i>2</i>, <i>4eva</i> and <i>tmrw</i>) and apostrophes used in contraction forms (e.g. <i>yoou've</i>) are considered for normalisation. Tokens involved with hyphens, single quotes and other contractions are ignored.</li>
    <li>Domain specific entities are ignored even if they are in non-standard forms, e.g., <i>#ttyl</i>, <i>@nyc</i></li>
    <li>It is possible a tweet has no non-standard words, however, your system shall still output a tokenised tweet without any changes.</li>
    <li>Proper nouns shall be kept untouched even if they are not in the given lexicon, e.g., <i>Twitter</i>.</li>
    <li>Your normalisations shall be in American spelling, e.g., <i>tokenize</i> rather than <i>tokenise</i>.</li>
    <li>In some corner cases, it is hard to judge whether a token is a non-standard word or its normalised form is hard to be determined, then your system shall keep it untouched.</li>
</ol>
<p>A more detailed annotation guideline is also provided <a href="/files/annotation_guideline_v1.1.pdf" target="_blank">here</a></p>

<p>For your conventinence and the consistency of evaluation, we pre-tokenised tweets and provided them in JSON format. A training data file is a JSON list in which each item represents a tweet. A tweet is a JSON dict containing four fields: index (the index in the annotation), tid (tweet id), input (a list of case sensitive tokens to be normalised), and output (a list of lowercased tokens that are normalised). 
The test data for evaluation follows the same format as the training data, but it does NOT have output fields, your task is to add output fields in the test data from your normalisation system.
Note the output fields are lowercased.
</p>

<p>
A mock-up example is shown for demonstration. <i>Jst</i>, <i>lol</i> and <i>l o v e</i> are normalised to <i>just</i>, <i>laughing out loud</i> and <i>love</i>, respectively.
</br>

{
  'tid': '971011879910802432',
  'index': '1064',
  'input': [
    'Jst',
    'read',
    'a',
    'tweet',
    'lol',
    'and',
    'l',
    'o',
    'v',
    'e',
    'it'
  ],
  'output': [
    'just',
    'read',
    'a',
    'tweet',
    'laughing out loud',
    'and',
    'love',
    '',
    '',
    '',
    'it'
  ]
}
</p>

<p>The evaluation metrics are Precision, Recall and F1 score, and the submissions will be evaluated in two modes separately.</p>
<ul>
<li>
Task 1: Constrained mode (cm)
</br>
Participants can only use provided training data to perform the text normalisation task. Participants can use any off-the-shelf tools (e.g., Twitter POS tagger).
</li>
<li>
Task 2: Unconstrained mode (um)
</br>
Participants can use any publicly accessible data and tools to perform the text normalisation task.
</li>
</ul>

<p>Please submit your results to <b>lexnorm2015@gmail.com</b> by attachments. The attachments shall be plain JSON files and are named by team and mode. For instance, if my registered team name is "demo", and I competed in both models, I shall have the following two files as attachments: "demo.cm.json" and "demo.um.json".
You may submit multiple times, but your last submission before the deadline will be used for evaluation.
</p>


<hr>
<a id="resource" > <h2 style="padding-top:50px; margin-top:-50px;">Resources</h2></a>

<ul>
    <li>Canonical English lexicon: <a href="/files/scowl.american.70" target="_blank">English lexicon</a></li>
    <li>Lexical normalisation dictionary: <a href="http://people.eng.unimelb.edu.au/tbaldwin/etc/emnlp2012-lexnorm.tgz" target="_blank">UniMelb</a>, <a href="http://www.hlt.utdallas.edu/~yangl/data/Text_Norm_Data_Release_Fei_Liu/" target="_blank">UTDallas</a></li>
    <li>Tweet POS taggers: <a href="http://code.google.com/p/ark-tweet-nlp/downloads/list" target="_blank">CMU</a>, <a href="https://gate.ac.uk/wiki/twitter-postagger.html" target="_blank">Sheffield</a></li>
    <li>Tweet Dependency parsers: <a href="https://sourceforge.net/p/tweeboparser/" target="_blank">CMU</a></li>
</ul>

<hr>
<a id="date" > <h2 style="padding-top:50px; margin-top:-50px;">Important Dates </h2></a>
Note: All deadlines are 11:59PM Pacific Time
<ul>
    <li><a href="" target="_blank">Training data and annotations released: April 7, 2015</a></li>
    <li>Test data released: May 7, 2015</li>
    <li>Result submission: May 11, 2015</li>
    <li>Shared-task results and annotations for test data: May 14, 2015</li>
    <li>Shared-task paper/poster submission: May 31, 2015</li>
    <li>Shared-task paper/poster review due: June 14, 2015</li>
    <li>Shared-task paper/poster camera ready: June 21, 2015</li>
    <li>Mailing list for the shared task: <a href="https://groups.google.com/forum/#!members/lexical-normalisation-for-english-tweets">Here</a></li>
</ul>
</hr>


<hr>
<a id="committee" >	<h2  style="padding-top:50px; margin-top:-50px;">Organizer</h2></a>
	<ul class="list-unstyled">
	<li><a href="http://tq010or.github.io/index.html">Bo Han</a> (IBM Research)  </li>
	<li><a href="http://people.eng.unimelb.edu.au/tbaldwin">Tim Baldwin</a> (University of Melbourne)  </li>
	</ul>
</hr>

<hr>
<a id="reference" ><h2 style="padding-top:50px; margin-top:-50px;">References</h2></a>
<ol>
    <li>Aw, AiTi, Min Zhang, Juan Xiao, and Jian Su. 2006. A phrase-based statistical model for SMS text normalization. In Proceedings of COLING/ACL 2006 , 33–40, Sydney, Australia.</li>
    <li>Richard Beaufort, Sophie Roekhaut, Louise-Amélie Cougnon, and Cédrick Fairon. 2010. A hybrid rule/model-based finite-state framework for normalizing SMS messages. In Proceedings of the 48th Annual Meeting of the ACL (ACL 2010), 770–779, Uppsala, Sweden.</li>
    <li>Choudhury, Monojit, Rahul Saraf, Vijit Jain, Animesh Mukherjee, Sudeshna Sarkar, and Anupam Basu. 2007. Investigation and modeling of the structure of texting language. International Journal on Document Analysis and Recognition 10.157–174.</li>
    <li>Chrupala, Grzegorz. 2014. Normalizing tweets with edit scripts and recurrent neural embeddings. In Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (ACL 2014), 680–686, Baltimore, USA.</li>
    <li>Contractor, Danish, Tanveer A. Faruquie, and L. Venkata Subramaniam. 2010. Unsupervised cleansing of noisy text. In Proceedings of the 23rd International Conference on Computational Linguistics (COLING 2010), 189– 196, Beijing, China.</li>
    <li>Cook, Paul, and Suzanne Stevenson. 2009. An unsupervised model for text message normalization. In Proceedings of the Workshop on Computational Approaches to Linguistic Creativity (CALC ’09), 71–78, Boulder, USA.</li>
    <li>Foster, Jennifer. 2010. “cba to check the spelling” investigating parser performance on discussion forum posts. In Proceedings of Human Language Technologies: The 11th Annual Conference of the North American Chapter of the Association for Computational Linguistics (NAACL HLT 2010), 381–384, Los Angeles, USA.</li>
    <li>Gouws, Stephan, Dirk Hovy, and Donald Metzler. 2011a. Unsupervised mining of lexical variants from noisy text. In Proceedings of the First Workshop on Unsupervised Learning in NLP , 82–90, Edinburgh, UK.</li>
    <li>Bo Han and Timothy Baldwin. 2011. Lexical normalisation of short text messages: Makn sens a #twitter. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies (ACL-HLT 2011), pages 368– 378, Portland, USA.</li>
    <li>Bo Han, Paul Cook and Timothy Baldwin. 2012. Automatically constructing a normalisation dictionary for microblogs. In Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP-CoNLL 2012), pages 421–432, Jeju, Republic of Korea.</li>
    <li>Bo Han, Paul Cook and Timothy Baldwin. 2013. Lexical Normalisation of Short Text Messages. In ACM Transactions on Intelligent Systems and Technology (TIST 2013) , 4(1), pages 5:1{27}.</li>
    <li>Hassan, Hany, and Arul Menezes. 2013. Social text normalization using contextual graph random walks. In Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (ACL 2013), 1577–1586, Sofia, Bulgaria.</li>
    <li>Catherine Kobus, François Yvon, and Géraldine Damnati. 2008. Normalizing SMS: are two metaphors better than one? In Proceedings of the 22nd International Conference on Computational Linguistics (COLING 2008), 441– 448, Manchester, UK.</li>
    <li>Li, Chen, and Yang Liu. 2012. Improving text normalization using character-blocks based models and system combination. In Proceedings of the 24th International Conference on Computational Linguistics (COLING 2012), 1587–1602, Mumbai, India.</li>
    <li>Ling, Wang, Chris Dyer, Alan W Black, and Isabel Trancoso. 2013. Paraphrasing 4 microblog normalization. In Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing (EMNLP 2013), 73–84, Seattle, USA.</li>
    <li>Liu, Fei, Fuliang Weng, and Xiao Jiang. 2012. A broad-coverage normalization system for social media language. In Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics (ACL 2012), 1035–1044, Jeju Island, Korea.</li>
    <li>Liu, Fei, Fuliang Weng, Bingqing Wang, and Yang Liu. 2011a. Insertion, dele- tion, or substitution? Normalizing text messages without pre-categorization nor supervision. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies (ACL HLT 2011), 71–76, Portland, USA.</li>
    <li>Pennell, Deana, and Yang Liu. 2011a. A character-level machine translation approach for normalization of SMS abbreviations. In Proceedings of the 5th International Joint Conference on Natural Language Processing (IJCNLP 2011), 974–982, Chiang Mai, Thailand.</li>
    <li>Pennell, Deana, and Yang Liu. 2011b. Toward text message normalization: Modeling abbreviation generation. In Proceedings of 2011 IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP ’11), 5364–5367, Prague, Czech Republic.</li>
    <li>Porta, Jordi, and Jos e using finite-state transducers. In Proceedings of the Tweet Normalization Workshop co-located with 29th Conference of the Spanish Society for Natural Language Processing (SEPLN 2013), volume 1086, 49–53, Madrid, Spain.</li>
    <li>Sproat, Richard, Alan W. Black, Stanley Chen, Shankar Kumar, Mari Ostendorf, and Christopher Richards. 2001. Normalization of non-standard words. Computer Speech and Language 15.287–333.</li>
    <li>Wang, Pidong, and Hwee Tou Ng. 2013. A beam-search decoder for normalization of social media text with application to machine translation. In Proceedings of the 2013 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL HLT 2013), 471–481, Atlanta, USA.</li>
    <li>Xu, Wei, Alan Ritter, and Ralph Grishman. 2013. Gathering and generating paraphrases from Twitter with application to normalization. In Proceedings of the Sixth Workshop on Building and Using Comparable Corpora, 121–128, Sofia, Bulgaria.</li>
    <li>Xue, Zhenzhen, Dawei Yin, and Brian D. Davison. 2011. Normalizing micro- text. In Proceedings of the AAAI-11 Workshop on Analyzing Microtext, 74–79, San Francisco, USA.</li>
    <li>Yang, Yi, and Jacob Eisenstein. 2013. A log-linear model for unsupervised text normalization. In Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing (EMNLP 2013), 61–72, Seattle, USA.</li>
    <li>Zhang, Congle, Tyler Baldwin, Howard Ho, Benny Kimelfeld, and Yun- yao Li. 2013. Adaptive parser-centric text normalization. In Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (ACL 2013), 1159–1168, Sofia, Bulgaria.</li>
    <li>Zhu, Conghui, Jie Tang, Hang Li, Hwee Tou Ng, and Tiejun Zhao. 2007. A unified tagging approach to text normalization. In Proceedings of the 45th Annual Meeting of the Association for Computational Linguistics (ACL 2007), 688–695, Prague, Czech Republic.</li>
<ol>
</hr>

<br/>
<br/>
<br/>
<br/>

    </div> <!-- /container -->


    <!-- Bootstrap core JavaScript
    ================================================== -->
    <!-- Placed at the end of the document so the pages load faster -->
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.1/jquery.min.js"></script>
    <script src="./dist/js/bootstrap.min.js"></script>
    <!-- IE10 viewport hack for Surface/desktop Windows 8 bug -->
    <script src="../../assets/js/ie10-viewport-bug-workaround.js"></script>
  </body>
</html>

